{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Selecting dimensionality reduction with Pipeline and GridSearchCV\n",
    "\n",
    "\n",
    "This example constructs a pipeline that does dimensionality\n",
    "reduction followed by prediction with a support vector\n",
    "classifier. It demonstrates the use of ``GridSearchCV`` and\n",
    "``Pipeline`` to optimize over different classes of estimators in a\n",
    "single CV run -- unsupervised ``PCA`` and ``NMF`` dimensionality\n",
    "reductions are compared to univariate feature selection during\n",
    "the grid search.\n",
    "\n",
    "Additionally, ``Pipeline`` can be instantiated with the ``memory``\n",
    "argument to memoize the transformers within the pipeline, avoiding to fit\n",
    "again the same transformers over and over.\n",
    "\n",
    "Note that the use of ``memory`` to enable caching becomes interesting when the\n",
    "fitting of a transformer is costly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration of ``Pipeline`` and ``GridSearchCV``\n",
    "##############################################################################\n",
    " This section illustrates the use of a ``Pipeline`` with\n",
    " ``GridSearchCV``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Robert McGibbon, Joel Nothman, Guillaume Lemaitre\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    # the reduce_dim stage is populated by the param_grid\n",
    "    ('reduce_dim', None),\n",
    "    ('classify', LinearSVC())\n",
    "])\n",
    "\n",
    "N_FEATURES_OPTIONS = [2, 4, 8]\n",
    "C_OPTIONS = [1, 10, 100, 1000]\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'classify__C': C_OPTIONS\n",
    "    },\n",
    "]\n",
    "reducer_labels = ['PCA', 'NMF', 'KBest(chi2)']\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=5, n_jobs=1, param_grid=param_grid)\n",
    "digits = load_digits()\n",
    "grid.fit(digits.data, digits.target)\n",
    "\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])\n",
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "               (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "plt.figure()\n",
    "COLORS = 'bgrcmyk'\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel('Digit classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caching transformers within a ``Pipeline``\n",
    "##############################################################################\n",
    " It is sometimes worthwhile storing the state of a specific transformer\n",
    " since it could be used again. Using a pipeline in ``GridSearchCV`` triggers\n",
    " such situations. Therefore, we use the argument ``memory`` to enable caching.\n",
    "\n",
    " .. warning::\n",
    "     Note that this example is, however, only an illustration since for this\n",
    "     specific case fitting PCA is not necessarily slower than loading the\n",
    "     cache. Hence, use the ``memory`` constructor parameter when the fitting\n",
    "     of a transformer is costly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from joblib import Memory\n",
    "\n",
    "# Create a temporary folder to store the transformers of the pipeline\n",
    "cachedir = mkdtemp()\n",
    "memory = Memory(cachedir=cachedir, verbose=10)\n",
    "cached_pipe = Pipeline([('reduce_dim', PCA()),\n",
    "                        ('classify', LinearSVC())],\n",
    "                       memory=memory)\n",
    "\n",
    "# This time, a cached pipeline will be used within the grid search\n",
    "grid = GridSearchCV(cached_pipe, cv=5, n_jobs=1, param_grid=param_grid)\n",
    "digits = load_digits()\n",
    "grid.fit(digits.data, digits.target)\n",
    "\n",
    "# Delete the temporary cache before exiting\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``PCA`` fitting is only computed at the evaluation of the first\n",
    "configuration of the ``C`` parameter of the ``LinearSVC`` classifier. The\n",
    "other configurations of ``C`` will trigger the loading of the cached ``PCA``\n",
    "estimator data, leading to save processing time. Therefore, the use of\n",
    "caching the pipeline using ``memory`` is highly beneficial when fitting\n",
    "a transformer is costly.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
